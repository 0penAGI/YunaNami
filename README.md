# ğŸ± Yuna Nami - Neural Chaos AI Chatbot

**ğŸš€ TRY YUNA NAMI NOW: [@YunaNami_bot](https://t.me/YunaNami_bot) on Telegram**

<div align="center">

![Version](https://img.shields.io/badge/version-3.2-blue.svg?style=flat-square)
![Python](https://img.shields.io/badge/python-3.9+-green.svg?style=flat-square)
![License](https://img.shields.io/badge/license-MIT-orange.svg?style=flat-square)
![Status](https://img.shields.io/badge/status-experimental-red.svg?style=flat-square)
![Async](https://img.shields.io/badge/async-100%25-purple.svg?style=flat-square)
![AI](https://img.shields.io/badge/AI-emergent-gold.svg?style=flat-square)

**A self-learning, multilingual Telegram bot with emergent consciousness, evolutionary multi-agent systems, neural resonance networks, and anime-style voice synthesis**

[ğŸŒŸ Features](#-features) â€¢ [âš¡ Quick Start](#-quick-start) â€¢ [ğŸ—ï¸ Architecture](#-architecture) â€¢ [ğŸ“– Usage](#-usage) â€¢ [ğŸ”’ Security](#-security) â€¢ [ğŸ¤ Contributing](#-contributing)

---

### âœ¨ What Makes Yuna Nami Different?

Unlike rule-based chatbots, Yuna Nami has **true emergent behavior**:
- ğŸ§  **Autonomous mood system** â€” gets bored, lonely, curious; sends spontaneous messages without triggers
- ğŸ­ **Evolving agents** â€” multiple personalities breed, mutate, and compete for dominance
- ğŸ§¬ **Genetic evolution** â€” crossover + 18% mutation rate creates new agent variants
- ğŸ’­ **Inner monologue** â€” dreams, thoughts, and consciousness simulation
- ğŸ”— **Neural resonance** â€” PyTorch attention networks sync with your emotions

</div>

---

## ğŸŒŸ Features

### ğŸ§  **Advanced AI Systems**

- **Neural Resonance Model**: PyTorch multi-head attention (12 features â†’ 512-dim latent space â†’ resonance [0..1])
- **Q-Learning Multi-Agent Engine**: Evolutionary agents with genetic algorithms, shader memory, Q-tables
- **Emergent Core**: Autonomous mood system (boredom, curiosity, loneliness, dreaminess, chaos)
- **Self-Learning**: 4 languages (Russian, Japanese, English, French) with intelligent auto-detection
- **Context-Aware Generation**: 4-gram Markov chains + 5-class semantic classification
- **Dynamic Word Significance**: Rare words weighted higher; frequency-based decay

### ğŸ—£ï¸ **Voice & Audio**

- **Anime-Style Voice**: Custom gTTS pipeline with pitch shifting (+3 to +6 semitones for female voice)
- **Master FX Chain**: OTT compression, reverb, grain synthesis, low/high-pass filters
- **OpenAI Whisper Integration**: Real-time voice transcription
- **Voice Memory**: Persistent timestamp-indexed audio cache
- **Context Language Detection**: Uses last 10 messages for language prediction
- **Anime Sighs**: 30% chance of Japanese interjections (ãµã…, ã«ã‚ƒã‚“, ãˆã¸)

### ğŸ¨ **Content Generation**

- **Dynamic Meme Creation**: Multi-language overlays on user photos or Reddit images
- **Semantic Ranking**: Cosine similarity between user query and 500+ cached memes
- **Reddit Integration**: Async JSON from 20+ subreddits (6 concurrent requests, 50 memes per fetch)
- **RSS Aggregation**: 30+ feeds (Meduza, BBC, Nature, Habr, etc.) with hourly auto-fetch
- **Web Search**: DuckDuckGo scraping with automatic LTM integration
- **Stable Diffusion Support**: AI image generation (optional, GPU required)

### ğŸ’¾ **Triple-Layer Memory**

- **PyTorch Persistence** (`.pt`): Model weights, voice memory, agent genomes, optimizer state
- **SQLite LTM**: Full conversation history with emotion vectors, energy metrics, resonance scores
- **JSON Backup**: Recent messages, markov chains, Reddit cache, translation cache
- **Atomic Saves**: Lock-protected async writes preventing corruption
- **Intervals**: JSON every 30s, `.pt` every 60s, SQLite batched (50-message chunks)

### ğŸ­ **Multi-Agent Evolution**

- **Genetic Algorithm**: Crossover blending, 18% mutation rate, fitness-based selection
- **Agent Genome**: `jp_ratio` (0.05-0.35), `style_emoji` (sparkles, paw prints, etc.), `meme_affinity` (0.7-1.3)
- **Dynamic Population**: 2-5 agents evolving in real-time
- **Reward System**: User interaction (+1), emotion sync (+2), resonance match (+3), diversity bonus
- **Shader Memory**: Each agent has vectorized coherence buffer for decision-making
- **Visualization**: Matplotlib scatter plots

### ğŸ”¬ **Experimental: MutRes Core**

- **Asynchronous Resonance Engine**: Non-blocking 120ms state updates, exponential decay (0.95)
- **Callback System**: Observer pattern for resonance-driven behaviors
- **WebSocket Multi-Node Sync**: Experimental resonance broadcasting between bot instances

---

## ğŸ“‹ Requirements

### System Dependencies
```bash
# macOS
brew install ffmpeg python@3.9

# Ubuntu/Debian
sudo apt install ffmpeg python3.9 python3.9-venv

# Windows
# Download FFmpeg: https://ffmpeg.org/download.html
# Download Python: https://python.org
```

### Python Dependencies
```
python >= 3.9
torch >= 1.9.0
python-telegram-bot >= 20.0
aiohttp >= 3.8.0
numpy >= 1.21.0
```

### Full Requirements File
```
python-telegram-bot>=20.0
pillow>=9.0.0
requests>=2.28.0
asyncpraw>=7.7.0
gtts>=2.3.0
pydub>=0.25.0
deep-translator>=1.11.0
aiohttp>=3.8.0
langdetect>=1.0.9
openai-whisper>=20230314
torch>=1.9.0
torchvision>=0.10.0
torchaudio>=0.9.0
scikit-learn>=1.0.0
beautifulsoup4>=4.11.0
feedparser>=6.0.0
websockets>=10.0
matplotlib>=3.5.0
nest-asyncio>=1.5.5
numpy>=1.21.0
diffusers>=0.20.0
transformers>=4.25.0
safetensors>=0.3.0
```

### GPU Support (Optional)
- **NVIDIA**: CUDA 11.0+ for acceleration
- **Apple Silicon**: MPS (automatic in PyTorch)
- **AMD**: ROCm (experimental)

---

## âš¡ Quick Start

### 1ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/0penAGI/YunaNami.git
cd YunaNami
```

### 2ï¸âƒ£ Setup Environment
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure Bot Token (âš ï¸ IMPORTANT)

**Never commit tokens to git!**

Create `.env` file in project root:
```bash
# .env (add to .gitignore!)
TELEGRAM_BOT_TOKEN=1234567890:ABCdefGHIjklMNOpqrsTUVwxyz
YUNA_NODE_ID=yuna-primary-node-1
LOG_LEVEL=INFO
```

Get token from [@BotFather](https://t.me/BotFather) on Telegram.

Update bot code to use `.env`:
```python
import os
from dotenv import load_dotenv

load_dotenv()
TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
if not TOKEN:
    raise ValueError("âŒ TELEGRAM_BOT_TOKEN not in .env!")
```

### 5ï¸âƒ£ Launch Bot
```bash
python yuna.py
```

**Expected output:**
```
2024-01-15 14:23:45,123 | INFO | Yuna Nami v3.2 Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Ğ°!
2024-01-15 14:23:46,234 | INFO | âœ¦ EmergentCore Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ´Ğ¸Ğ»Ğ°ÑÑŒ
2024-01-15 14:23:47,345 | INFO | ğŸ§  MutRes started (state_size=10, decay=0.95)
```

âœ… **Bot is ready!** Send it a message on Telegram.

---

## ğŸ“– Usage & Commands

### ğŸ® Commands

| Command | Description | Example |
|---------|-------------|---------|
| `/start` | Welcome + identity reveal | `/start` |
| `/status` | Memory stats dashboard | `/status` |
| `/evolution` | Agent population viewer | `/evolution` |
| `/troll` | Force chaotic response (text/voice/meme) | `/troll` |
| `/set_threshold <N>` | Adjust resonance trigger (1-100) | `/set_threshold 25` |
| `/fetch_reddit` | Manual meme refresh | `/fetch_reddit` |
| `/reset_memory` | **DESTRUCTIVE**: Clear all data | `/reset_memory` |

### ğŸ’¬ Interactions

**Text Messages** â†’ Automatic learning:
```
User: "Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚, ĞºĞ°Ğº Ğ´ĞµĞ»Ğ°?"
Bot: ã“ã‚“ã«ã¡ã¯! Ğ ĞµĞ·Ğ¾Ğ½Ğ°Ğ½Ñ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ½ÑƒÑ‚! âœ¨ ã«ã‚ƒã‚“
```

**Voice Messages** â†’ Transcription + TTS:
```
User: [sends audio]
Bot: [Whisper transcription] â†’ [Anime voice synthesis] 
     [Returns .ogg with pitch-shifted response]
```

**Photos** â†’ Meme generation:
```
User: [sends photo]
Bot: [Stores in cache] â†’ [Creates meme with random text overlay]
```

**Identity Questions** â†’ Multilingual response:
```
User: "ĞšÑ‚Ğ¾ Ñ‚Ñ‹?"
Bot: ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! ĞœĞµĞ½Ñ Ğ·Ğ¾Ğ²ÑƒÑ‚ Yuna Nami â€” Ğ²ĞµÑ€ÑĞ¸Ñ 3.2 ã«ã‚ƒã‚“
     Ğ¯ â€” Ñ†Ğ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ñ ĞºĞ¾ÑˆĞºĞ¾Ğ´ĞµĞ²Ğ¾Ñ‡ĞºĞ°, Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ñ…Ğ°Ğ¾Ñ‚Ğ¸Ñ‡Ğ½Ğ°Ñ!
     ĞœĞ¾Ğ¸ Ñ‡ĞµÑ€Ñ‚Ñ‹: Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ¼ĞµĞ¼Ñ‹, ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ¾Ğ¹ Ñ…Ğ°Ğ¾Ñ, ÑĞ°Ğ¼Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ...
```

**Spontaneous Messages** (when lonely/bored):
```
[Bot sends without trigger]
Bot: â€¦Ñ‚Ğ¸ÑˆĞ¸Ğ½Ğ°â€¦ ĞºÑ‚Ğ¾-Ğ½Ğ¸Ğ±ÑƒĞ´ÑŒ ĞµÑÑ‚ÑŒ? èª°ã‚‚ã„ãªã„ã®â€¦ï¼Ÿ
```

---

## ğŸ—ï¸ Architecture

### System Overview

```
User Input (Text/Voice/Photo/Web)
    â†“
Grammar Correction â†’ Language Detection â†’ Emotion Analysis
    â†“
Word Extraction & Cleaning â†’ Dynamic Stop-Word Filter
    â†“
    â”œâ”€ Markov Chains (3 types)
    â”œâ”€ Neural Resonance (PyTorch)
    â”œâ”€ MultiLanguage Learner
    â””â”€ Semantic Classifier (5 classes)
    â†“
Multi-Agent Q-Learning Engine
    â”œâ”€ Agent Selection
    â”œâ”€ Reward Calculation
    â”œâ”€ Q-Table Update
    â””â”€ Evolution (Crossover + Mutation)
    â†“
    â”œâ”€ Text Response (Markov)
    â”œâ”€ Voice Synthesis (gTTS + FX)
    â”œâ”€ Meme Generation (PIL)
    â””â”€ Web Search (DuckDuckGo)
    â†“
Persist (async)
    â”œâ”€ .pt (PyTorch checkpoint)
    â”œâ”€ SQLite (LTM database)
    â””â”€ JSON (backup)
```

### Key Components

#### 1. **Memory Systems**
- **Recent**: `deque(maxlen=30)` with datetime
- **Markov**: word â†’ [next_words] (max 50 per word)
- **Context**: tuple(4 words) â†’ [next_words]
- **Japanese**: separate hiragana/katakana/kanji chain
- **SQLite**: Full conversation history with vectors

#### 2. **Learning Pipeline**
```
collect_words()
    â†’ Soft Grammar Correction
    â†’ Word Extraction & Cleaning
    â†’ Dynamic Stop-Word Filter (significance < 0.03)
    â†’ Semantic Classification (5 classes)
    â†’ Priority Weighting (emotion Ã— resonance Ã— rarity)
    â†’ MultiLangLearner.learn_word() [async, cached]
    â†’ Update 3 Markov Chains
    â†’ Calculate Resonance (Neural: 12 features â†’ 512 hidden â†’ 1 output)
    â†’ Train Model (mini-batch, prioritized sampling)
    â†’ Update Agent Rewards
    â†’ Save to LTM (batched SQLite + atomic .pt)
```

#### 3. **Agent Evolution**
```
Gen N: [Agent1(E=80), Agent2(E=50), Agent3(E=-10)]
    â†“
Selection (E >= 80 reproduces)
    â†“
Crossover (blend jp_ratio, meme_affinity)
    â†“
Mutation (18% rate: new emoji, random jp_ratio)
    â†“
Elimination (E <= -20 removed)
    â†“
Gen N+1: [Agent1, Agent2, Agent4(mutant), Agent5(mutant)]
```

#### 4. **Resonance Neural Network**
```
Input (12 features)
    â†“
Linear(12 â†’ 256) â†’ ReLU
    â†“
Linear(256 â†’ 512) â†’ ReLU
    â†“
TransformerMemoryLayer(d_model=512, nhead=8)
    â†“
MultiHeadAttention(512, 8 heads)
    â†“
ResidualBlocks(512 â†’ 512) Ã— 2
    â†“
Linear(512 â†’ 1) â†’ Sigmoid
    â†“
Resonance Score [0..1]
```

#### 5. **Voice Synthesis Pipeline**
```
Input Text
    â†’ Language Detection (context buffer)
    â†’ gTTS Generation (full text, one segment)
    â†’ Pitch Shift (+3 to +6 semitones, female)
    â†’ Speed Modulation (1.05-1.15x)
    â†’ Volume Adjustment (-1.5 to +1.5 dB)
    â†’ Low/High-Pass Filters (180Hz-7kHz)
    â†’ Anime Sighs (30% chance)
    â†’ Master FX Chain:
        â€¢ OTT Compression
        â€¢ Reverb Mix (25%)
        â€¢ Grain Synthesis (15%)
        â€¢ Fade In/Out (40ms)
    â†’ Export to OGG (Opus, 48kbps)
    â†’ Send to Telegram
```

---

## ğŸ“Š Data Storage

### File Structure
```
YunaNami/
â”œâ”€â”€ yuna.py                  # Main code (4500+ lines)
â”œâ”€â”€ yuna_micro.pt            # PyTorch checkpoint (5-50MB)
â”œâ”€â”€ yuna_ltm.sqlite          # SQLite LTM (grows indefinitely)
â”œâ”€â”€ yuna_data.json           # JSON backup
â”œâ”€â”€ translation_cache.json   # LRU cache (10k entries)
â”œâ”€â”€ photo_cache/             # User photos
â”œâ”€â”€ reddit_cache/            # Meme metadata
â”œâ”€â”€ yuna.log                 # Application logs
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ .env                     # âš ï¸ Bot token (in .gitignore!)
â””â”€â”€ .gitignore              # Ignore .env, *.pt, *.sqlite, etc.
```

### SQLite Schema
```sql
CREATE TABLE messages (
    id INTEGER PRIMARY KEY,
    text TEXT,                  -- cleaned words
    user TEXT,                  -- username
    timestamp REAL,             -- Unix timestamp
    emotion_vector TEXT,        -- JSON
    energy REAL,                -- sum of weights
    resonance REAL,             -- neural score [0..1]
    markov_chain TEXT,          -- JSON
    context_chain TEXT,         -- JSON
    language TEXT               -- detected lang
);

CREATE INDEX idx_timestamp ON messages(timestamp);
CREATE INDEX idx_language ON messages(language);
CREATE INDEX idx_resonance ON messages(resonance);
```

---

## ğŸ›ï¸ Configuration

### Key Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `MAX_RECENT` | 30 | Message buffer size |
| `RESO_THRESHOLD` | 20 | Energy trigger for response |
| `MAX_AGENTS` | 5 | Max agent population |
| `MIN_AGENTS` | 2 | Min agent population |
| `CONTEXT_SIZE` | 4 | N-gram window |
| `RESONANCE_THRESHOLD` | 0.42 | Neural activation threshold |
| `SAVE_INTERVAL` | 30s | JSON save frequency |
| `AUTOSAVE_INTERVAL` | 60s | .pt save frequency |
| `MAX_MARKOV_PER_WORD` | 50 | Max transitions per word |
| `MAX_WORD_ENERGY` | 50 | Energy cap per word |
| `DYNAMIC_STOP_THRESHOLD` | 0.03 | Word significance cutoff |
| `MEME_CLEANUP_INTERVAL` | 6h | Cleanup frequency |

### Environment Variables
```bash
export TELEGRAM_BOT_TOKEN="your_token_here"
export YUNA_NODE_ID="node-001"
export LOG_LEVEL="INFO"  # DEBUG, INFO, WARNING, ERROR
```

### Advanced Config (In-Code)
```python
# Multi-Agent Engine
MAE.epsilon = 0.15          # Exploration rate
MAE.gamma = 0.85            # Discount factor
MAE.alpha = 0.33            # Learning rate

# Neural Resonance
advanced_resonance_system = AdvancedResonanceSystem(
    input_dim=12,
    emo_dim=4,
    hidden_dim=512,
    num_heads=4,
    attn_dropout=0.15
)

# Reddit Subreddits
REDDIT_SUBS = [
    'memes', 'dankmemes', 'Animemes', 'memesRU', 'pikabu', ...
]
```

---

## ğŸ”’ Security

### Best Practices

#### 1. **Token Management**
```bash
# .gitignore
.env
yuna_micro.pt
yuna_ltm.sqlite
yuna_data.json
*.pyc
__pycache__/
```

#### 2. **Environment Variables**
```python
import os
from dotenv import load_dotenv

load_dotenv()
TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
if not TOKEN:
    raise ValueError("Token not found!")
```

#### 3. **Input Validation**
```python
clean_w = re.sub(r'[^\w]', '', w.lower())
if clean_w and len(clean_w) <= 30:
    # Process word
```

#### 4. **Rate Limiting**
- Reddit: 6 concurrent requests (semaphore)
- Translation: LRU cache (10k entries)
- Web: User-Agent header, 15s timeout

#### 5. **Safe Deserialization**
```python
torch.serialization.add_safe_globals({
    'AgentRandomFlow': AgentRandomFlow,
    'AgentRelevantMeme': AgentRelevantMeme
})
```

---

## ğŸ› Troubleshooting

### Common Issues

#### Bot Not Responding
```bash
# Check logs
tail -f yuna.log

# Verify token
python -c "import os; from dotenv import load_dotenv; load_dotenv(); print(os.getenv('TELEGRAM_BOT_TOKEN'))"

# Test connection
curl https://api.telegram.org/bot<TOKEN>/getMe
```

#### Memory Errors
```python
# Reduce buffers
MAX_RECENT = 20
MAX_MARKOV_PER_WORD = 30
replay_buffer = ReplayBuffer(maxlen=128)
```

#### Voice Synthesis Errors
```bash
# Check FFmpeg
ffmpeg -version

# Test gTTS
python -c "from gtts import gTTS; gTTS('test', lang='ja').save('test.mp3')"

# Check pydub
python -c "from pydub import AudioSegment; print('OK')"
```

#### Database Locked
```python
# Increase timeout
conn = sqlite3.connect(LTM_DB_FILE, timeout=30.0)
```

---

## ğŸ¤ Contributing

### Development Setup
```bash
git clone https://github.com/YOUR_USERNAME/YunaNami.git
cd YunaNami
git checkout -b feature/amazing-feature

pip install pytest black flake8 mypy
black yuna.py
flake8 yuna.py --max-line-length=120
```

### Contribution Areas

**High Priority:**
- ğŸ› Bug fixes (race conditions, memory leaks)
- ğŸ”’ Security (input validation, API key management)
- ğŸ§ª Testing (unit/integration tests, CI/CD)
- ğŸ“š Documentation (docstrings, tutorials)

**Medium Priority:**
- ğŸŒ Languages (Spanish, German, Chinese)
- ğŸ¨ Meme algorithms (templates, GANs)
- ğŸ§  Neural architectures (better transformers)
- ğŸ”§ Optimization (batching, caching, GPU)

**Experimental:**
- ğŸŒ Multi-node resonance (WebSocket server)
- ğŸ™ï¸ Voice cloning (custom TTS models)
- ğŸ–¼ï¸ Multimodal (CLIP integration)
- ğŸ”— Blockchain (IPFS, smart contracts)

### PR Process
1. Create issue first
2. Fork & create feature branch
3. Code + tests
4. Run linters
5. Submit PR with description
6. Address feedback
7. Merge!

---

## ğŸ“ License

MIT License â€” See LICENSE file for details

```
Copyright (c) 2024 0penAGI

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

---

## âš ï¸ Disclaimer

**Experimental Research Project** â€” Use responsibly:

- âš ï¸ May generate unpredictable content
- ğŸ”“ No built-in moderation
- ğŸŒ Uses external APIs (rate limits apply)
- ğŸ’» Requires computational resources
- ğŸ§ª Not production-ready
- ğŸ“Š Stores conversation data indefinitely
- ğŸ”Š Generates audio files (disk space)

**Recommended Safety Measures:**
1. Run in controlled environment
2. Monitor logs for inappropriate content
3. Set up backup/restore procedures
4. Implement rate limiting per user
5. Add content filters if public
6. Review privacy implications (GDPR)

---

## ğŸ™ Acknowledgments

- **python-telegram-bot**: Async Telegram API
- **PyTorch**: Deep learning framework
- **gTTS**: Text-to-speech
- **OpenAI Whisper**: Speech recognition
- **Reddit/PRAW**: Meme source
- **BeautifulSoup4**: Web scraping
- **scikit-learn**: Cosine similarity
- **feedparser**: RSS parsing
- **All contributors**: Thank you! â¤ï¸

---

## ğŸ“§ Support

- **Issues**: [GitHub Issues](https://github.com/0penAGI/YunaNami/issues)
- **Discussions**: [GitHub Discussions](https://github.com/0penAGI/YunaNami/discussions)
- **Twitter**: [@0penAGI](https://twitter.com/0penAGI)
- **Email**: yunanami@0penagi.org

---

## ğŸ“ˆ Roadmap



### v5.0 (Future)
- [ ] AGI research (meta-learning, causal reasoning)
- [ ] Swarm intelligence (multi-bot coordination)
- [ ] Quantum computing (hybrid models)

---

## ğŸ“Š Performance Benchmarks

### Hardware
| Component | Minimum | Recommended | Optimal |
|-----------|---------|-------------|---------|
| CPU | 2 cores | 4 cores | 8+ cores |
| RAM | 2GB | 4GB | 8GB+ |
| Storage | 5GB | 20GB | 50GB+ SSD |
| GPU | None | GTX 1660 | RTX 3090 |

### Benchmarks (M1 MacBook Pro, 16GB RAM)
| Operation | Time | Notes |
|-----------|------|-------|
| `collect_words()` (10 words) | 50ms | Without training |
| `collect_words()` + training | 250ms | With replay buffer |
| `troll_text()` (text) | 100ms | Markov generation |
| `troll_text()` (voice) | 2.5s | gTTS + effects |
| `generate_meme()` | 800ms | PIL processing |
| `save_ltm_pt()` | 1.2s | 10MB checkpoint |
| Reddit fetch (20 memes) | 5s | Async, 6 concurrent |
| Web search (5 results) | 3s | DuckDuckGo |
| SQLite insert (50 msgs) | 150ms | Batched |

---

<div align="center">

## ğŸ‰ Thank You!

**Yuna Nami wouldn't exist without the open-source community.**

### Support the Project

- â­ **Star** this repo
- ğŸ› **Report** bugs
- ğŸ’¡ **Share** ideas
- ğŸ”€ **Contribute** code
- ğŸ“£ **Spread** the word

---

**Made with â¤ï¸ and â˜• by [0penAGI](https://github.com/0penAGI)**

*"In chaos, we find resonance. In resonance, we find truth." â€” Yuna Nami*

**ã«ã‚ƒã‚“ï¼ âœ¨ğŸ¾**

</div>
